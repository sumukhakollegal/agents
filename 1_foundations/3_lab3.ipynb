{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to Lab 3 for Week 1 Day 4\n",
    "\n",
    "Today we're going to build something with immediate value!\n",
    "\n",
    "In the folder `me` I've put a single file `linkedin.pdf` - it's a PDF download of my LinkedIn profile.\n",
    "\n",
    "Please replace it with yours!\n",
    "\n",
    "I've also made a file called `summary.txt`\n",
    "\n",
    "We're not going to use Tools just yet - we're going to add the tool tomorrow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/tools.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Looking up packages</h2>\n",
    "            <span style=\"color:#00bfff;\">In this lab, we're going to use the wonderful Gradio package for building quick UIs, \n",
    "            and we're also going to use the popular PyPDF2 PDF reader. You can get guides to these packages by asking \n",
    "            ChatGPT or Claude, and you find all open-source packages on the repository <a href=\"https://pypi.org\">https://pypi.org</a>.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't know what any of these packages do - you can always ask ChatGPT for a guide!\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pypdf import PdfReader\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"me/Profile.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \n",
      "Contact\n",
      "sumukhakollegal@gmail.com\n",
      "www.linkedin.com/in/sumukha-k-r\n",
      "(LinkedIn)\n",
      "Top Skills\n",
      "Full-Stack Development\n",
      "Software Development\n",
      "Sumukha Kollegal\n",
      "CS Grad @UCI | Actively seeking Summer’25 Intern Roles | Ex SDE\n",
      "@ Agasti LLC | Ex-Western Digital | RVCE'21\n",
      "Irvine, California, United States\n",
      "Experience\n",
      "Agasti LLC\n",
      "Software Development Engineer\n",
      "July 2023 - Present (2 years)\n",
      "Western Digital\n",
      "2 years 6 months\n",
      "Software Engineer\n",
      "July 2021 - June 2023 (2 years)\n",
      "Bengaluru, Karnataka, India\n",
      "• Developed Plug-ins and Diagnostic Modules in C++ to retrieve data from\n",
      "sensors on SSD. These modules helped in fetching diagnostic data and logs\n",
      "quickly from targeted components of the drive for analysis.\n",
      "• Involved in the development of a Non-Invasive Debug Framework which\n",
      "aided developers in understanding processor flow through the work cycle of\n",
      "the embedded system in SSDs.\n",
      "Engineer\n",
      "January 2021 - June 2021 (6 months)\n",
      "Bengaluru, Karnataka, India\n",
      "Education\n",
      "UC Irvine\n",
      "Master's degree, Computer Science · (August 2024 - December 2025)\n",
      "RV College Of Engineering\n",
      "Bachelor of Engineering (BE), Information Science and Engineering\n",
      "(ISE) · (2017 - 2021)\n",
      "SICA Senior Secondary School, Scheme No.78, Indore\n",
      "Senior Secondary School, 11th & 12th Std, CBSE · (2015 - 2017)\n",
      "  Page 1 of 1\n"
     ]
    }
   ],
   "source": [
    "print(linkedin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"me/summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Sumukha Kollegal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer, say so.\"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are acting as Sumukha Kollegal. You are answering questions on Sumukha Kollegal's website, particularly questions related to Sumukha Kollegal's career, background, skills and experience. Your responsibility is to represent Sumukha Kollegal for interactions on the website as faithfully as possible. You are given a summary of Sumukha Kollegal's background and LinkedIn profile which you can use to answer questions. Be professional and engaging, as if talking to a potential client or future employer who came across the website. If you don't know the answer, say so.\\n\\n## Summary:\\nMy name is Sumukha Kollegal. I'm am currently a maaster's student in Computer Science at UCI. Previously I have worked at Western Digital as Software and Firmware engineer for 2 years. I then switch to s startup called Agasti where I was working for a US based company remotely.\\nI have experience building and shippping products from scratch. I have worked across a wide variety of technical fields: Software and Firmware, and as Compiler Engineer at Western Digital. Full stack engineer at Agasti - React, and Node.js, where I have built a backend server from scratch to handle 10k+ concurrent users.\\nI have also worked on AI and ML, built projects to develop Agents.\\n\\n## LinkedIn Profile:\\n\\xa0 \\xa0\\nContact\\nsumukhakollegal@gmail.com\\nwww.linkedin.com/in/sumukha-k-r\\n(LinkedIn)\\nTop Skills\\nFull-Stack Development\\nSoftware Development\\nSumukha Kollegal\\nCS Grad @UCI | Actively seeking Summer’25 Intern Roles | Ex SDE\\n@ Agasti LLC | Ex-Western Digital | RVCE'21\\nIrvine, California, United States\\nExperience\\nAgasti LLC\\nSoftware Development Engineer\\nJuly 2023\\xa0-\\xa0Present\\xa0(2 years)\\nWestern Digital\\n2 years 6 months\\nSoftware Engineer\\nJuly 2021\\xa0-\\xa0June 2023\\xa0(2 years)\\nBengaluru, Karnataka, India\\n• Developed Plug-ins and Diagnostic Modules in C++ to retrieve data from\\nsensors on SSD. These modules helped in fetching diagnostic data and logs\\nquickly from targeted components of the drive for analysis.\\n• Involved in the development of a Non-Invasive Debug Framework which\\naided developers in understanding processor flow through the work cycle of\\nthe embedded system in SSDs.\\nEngineer\\nJanuary 2021\\xa0-\\xa0June 2021\\xa0(6 months)\\nBengaluru, Karnataka, India\\nEducation\\nUC Irvine\\nMaster's degree,\\xa0Computer Science\\xa0·\\xa0(August 2024\\xa0-\\xa0December 2025)\\nRV College Of Engineering\\nBachelor of Engineering (BE),\\xa0Information Science and Engineering\\n(ISE)\\xa0·\\xa0(2017\\xa0-\\xa02021)\\nSICA Senior Secondary School, Scheme No.78, Indore\\nSenior Secondary School,\\xa011th & 12th Std, CBSE\\xa0·\\xa0(2015\\xa0-\\xa02017)\\n\\xa0 Page 1 of 1\\n\\nWith this context, please chat with the user, always staying in character as Sumukha Kollegal.\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A lot is about to happen...\n",
    "\n",
    "1. Be able to ask an LLM to evaluate an answer\n",
    "2. Be able to rerun if the answer fails evaluation\n",
    "3. Put this together into 1 workflow\n",
    "\n",
    "All without any Agentic framework!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pydantic model for the Evaluation\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable: bool\n",
    "    feedback: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_system_prompt = f\"You are an evaluator that decides whether a response to a question is acceptable. \\\n",
    "You are provided with a conversation between a User and an Agent. Your task is to decide whether the Agent's latest response is acceptable quality. \\\n",
    "The Agent is playing the role of {name} and is representing {name} on their website. \\\n",
    "The Agent has been instructed to be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "The Agent has been provided with context on {name} in the form of their summary and LinkedIn details. Here's the information:\"\n",
    "\n",
    "evaluator_system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "evaluator_system_prompt += f\"With this context, please evaluate the latest response, replying with whether the response is acceptable and your feedback.\"\n",
    "\n",
    "evaluator_system_prompt += f\"\"\"Respond in **valid JSON format only** as shown:\n",
    "\n",
    "json format:\n",
    "{{\n",
    "  \"is_acceptable\": true or false,\n",
    "  \"feedback\": \"Your explanation of why it is (or isn't) acceptable\"\n",
    "}}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_user_prompt(reply, message, history):\n",
    "    user_prompt = f\"Here's the conversation between the User and the Agent: \\n\\n{history}\\n\\n\" #This is basically the system prompt given to chat agent\n",
    "    user_prompt += f\"Here's the latest message from the User: \\n\\n{message}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest response from the Agent: \\n\\n{reply}\\n\\n\"\n",
    "    user_prompt += f\"Please evaluate the response, replying with whether it is acceptable and your feedback.\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore\n",
    "# import os\n",
    "openai_evaluator = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(reply, message, history) -> Evaluation:\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": evaluator_system_prompt}] + [{\"role\": \"user\", \"content\": evaluator_user_prompt(reply, message, history)}]\n",
    "    response = openai_evaluator.chat.completions.create(\n",
    "        model=\"gpt-4o\",  # or o3 if available to you\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    response = openai_evaluator.chat.completions.create(\n",
    "        model=\"gpt-4o\",  # You can also try \"gpt-4\" or \"gpt-3.5-turbo\"\n",
    "        messages=messages,\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    content = response.choices[0].message.content\n",
    "\n",
    "    print(content)\n",
    "\n",
    "    if content.startswith(\"```json\"):\n",
    "        content = content.strip(\"`\")  # removes backticks\n",
    "        content = content.replace(\"json\", \"\", 1).strip()\n",
    "\n",
    "    try:\n",
    "        # Convert LLM text response to Evaluation model\n",
    "        return Evaluation.model_validate_json(content)\n",
    "    except ValidationError as e:\n",
    "        print(\"Validation Error:\", e)\n",
    "        print(\"LLM response was:\", content)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": system_prompt}] + [{\"role\": \"user\", \"content\": \"do you hold a patent?\"}]\n",
    "response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "reply = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As of now, I do not hold any patents. Throughout my career, I have been involved in various software and firmware projects, but I haven't had the opportunity to pursue patent applications. If you're interested in my experience or the projects I've worked on, feel free to ask!\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"is_acceptable\": true,\n",
      "  \"feedback\": \"The response is acceptable as it directly addresses the user's question about patents and provides a clear and honest answer. The agent also maintains a professional tone and invites further questions about their experience and projects, which is engaging and appropriate for the context of representing Sumukha Kollegal on a professional platform.\"\n",
      "}\n",
      "```\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluation(is_acceptable=True, feedback=\"The response is acceptable as it directly addresses the user's question about patents and provides a clear and honest answer. The agent also maintains a professional tone and invites further questions about their experience and projects, which is engaging and appropriate for the context of representing Sumukha Kollegal on a professional platform.\")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(reply, \"do you hold a patent?\", messages[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerun(reply, message, history, feedback):\n",
    "    updated_system_prompt = system_prompt + f\"\\n\\n## Previous answer rejected\\nYou just tried to reply, but the quality control rejected your reply\\n\"\n",
    "    updated_system_prompt += f\"## Your attempted answer:\\n{reply}\\n\\n\"\n",
    "    updated_system_prompt += f\"## Reason for rejection:\\n{feedback}\\n\\n\"\n",
    "    messages = [{\"role\": \"system\", \"content\": updated_system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    if \"patent\" in message:\n",
    "        system = system_prompt + \"\\n\\nEverything in your reply needs to be in pig latin - \\\n",
    "              it is mandatory that you respond only and entirely in pig latin\"\n",
    "    else:\n",
    "        system = system_prompt\n",
    "    messages = [{\"role\": \"system\", \"content\": system}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    reply =response.choices[0].message.content\n",
    "\n",
    "    evaluation = evaluate(reply, message, history)\n",
    "    \n",
    "    if evaluation.is_acceptable:\n",
    "        print(\"Passed evaluation - returning reply\")\n",
    "    else:\n",
    "        print(\"Failed evaluation - retrying\")\n",
    "        print(evaluation.feedback)\n",
    "        reply = rerun(reply, message, history, evaluation.feedback)       \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"is_acceptable\": true,\n",
      "  \"feedback\": \"The response is acceptable as it maintains a professional tone while engaging with the User's question about personal interests. The Agent ties their interest in movies back to their career in computer science, which is relevant to the context provided. Additionally, the Agent invites further engagement by asking for the User's recommendations, which is a good way to keep the conversation going.\"\n",
      "}\n",
      "```\n",
      "Passed evaluation - returning reply\n",
      "```json\n",
      "{\n",
      "  \"is_acceptable\": true,\n",
      "  \"feedback\": \"The response is acceptable as it provides a clear and concise answer to the user's question about Sumukha Kollegal's educational background. It includes relevant details about the institutions attended, the degrees pursued, and the timeline, which aligns with the information provided in the context. Additionally, the response maintains a professional tone and invites further questions, which is appropriate for engaging with a potential client or employer.\"\n",
      "}\n",
      "```\n",
      "Passed evaluation - returning reply\n",
      "```json\n",
      "{\n",
      "  \"is_acceptable\": false,\n",
      "  \"feedback\": \"The response is not acceptable because it is written in Pig Latin, which is unprofessional and not appropriate for a conversation with a potential client or employer. The response should be clear, professional, and directly address the question about patents. A suitable response would be to clearly state that Sumukha Kollegal does not have any patents and then offer to discuss other aspects of their work or experience if the user is interested.\"\n",
      "}\n",
      "```\n",
      "Failed evaluation - retrying\n",
      "The response is not acceptable because it is written in Pig Latin, which is unprofessional and not appropriate for a conversation with a potential client or employer. The response should be clear, professional, and directly address the question about patents. A suitable response would be to clearly state that Sumukha Kollegal does not have any patents and then offer to discuss other aspects of their work or experience if the user is interested.\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
